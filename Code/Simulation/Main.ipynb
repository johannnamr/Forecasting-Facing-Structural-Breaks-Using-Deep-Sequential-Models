{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4decb21e",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4f630e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "265c06b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:/Users/Meier/Institut für Statistik Dropbox/Johanna Meier/Structural Breaks + DL/Simulation/Python Code/' \n",
    "# path = 'C:/Users/Johan/Desktop/Local/'\n",
    "#path= 'C:/Users/Johan/Dropbox (Institut für Statistik)/Structural Breaks + DL/Simulation/Python Code/'\n",
    "#path = 'C:/Users/Slave 1/Desktop/Johanna/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8ba88a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "str_model = 'RNN' # 'RNN', 'LSTM', 'GRU', 'AR', 'ARIMA', 'GARCH'\n",
    "setting = 'AR' # 'AR', 'ARIMA', 'GARCH'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66e0c4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "reps = 1000         # number of repetitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9806bc50",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_length = 1000                              # length of simulated sample\n",
    "tau = np.array([0.1,0.45,0.9])  # break locations\n",
    "fac_beta = np.array([0.5,1,2])                 # break size factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4dafb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 0.1           # proportion of test set\n",
    "lags = 1                  # number of lags as features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "817196f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if setting == 'AR':\n",
    "    params = np.array([0.1,0.4,0.7,-0.4]) # AR (phi)\n",
    "if setting == 'ARIMA':\n",
    "    params = [np.array([0.4,-0.4]),np.array([0.3,-0.3])] # ARIMA (phi, theta)\n",
    "    params_list = list(itertools.product(params[0],params[1]))\n",
    "    print(params_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bfe0266",
   "metadata": {},
   "source": [
    "Run external notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9c01fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"Helper_functions.ipynb\" # notebook containing helper functions\n",
    "%run \"Simulate_data.ipynb\" # notebook containing simulation functions\n",
    "%run \"DL_models.ipynb\" # notebook containing sequential deep learning models\n",
    "%run \"Baseline_models.ipynb\" # notebook containing AR, ARIMA and GARCH models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98bc876a",
   "metadata": {},
   "source": [
    "Get names of simulation settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fddfe5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "str_sims = get_str_sims(tau, fac_beta) # get names of simulation settings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7beab80",
   "metadata": {},
   "source": [
    "Run simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83efb659",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulation start: Wed Mar  1 19:02:53 2023\n",
      "Repetition:  1\n",
      "Parameter combination:  1 / 4\n",
      "Dataset:  Ref ( 1 / 13 )\n",
      "Dataset:  Tau0.1Ref ( 2 / 13 )\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_15776\\1755962673.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     55\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Parameter combination: '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'/'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m             \u001b[0mdf_sim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_loop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstr_model\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel_params\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel_params\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnum_sim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstr_sims\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstr_sims\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mweight_decay\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m             \u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_sim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_15776\\288072188.py\u001b[0m in \u001b[0;36mtrain_loop\u001b[1;34m(model_name, model_params, num_sim, str_sims, path, learning_rate, weight_decay, lags, batch_size, n_epochs)\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[1;31m# train the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m         \u001b[0mmodel_out\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel_params\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'input_dim'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m         \u001b[1;31m#opt.plot_losses()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_15776\\955913207.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, train_loader, batch_size, n_epochs, n_features)\u001b[0m\n\u001b[0;32m     42\u001b[0m                 \u001b[0mx_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx_batch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_features\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m                 \u001b[0my_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_batch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m                 \u001b[0mb_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m                 \u001b[0mbatch_losses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mtraining_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_losses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_15776\\955913207.py\u001b[0m in \u001b[0;36mtrain_step\u001b[1;34m(self, x, y)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[1;31m# Computes gradients\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[1;31m# Updates parameters and zeroes gradients\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Programme\\anaconda3\\envs\\Env_StructuralBreaks\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    394\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    395\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 396\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    397\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    398\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Programme\\anaconda3\\envs\\Env_StructuralBreaks\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    173\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 175\u001b[1;33m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[0;32m    176\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m def grad(\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# start timer\n",
    "timer_start = time.time()\n",
    "print('Simulation start: %s' %time.ctime(int(timer_start)))\n",
    "\n",
    "# delete all files in Temp folder\n",
    "emtpy_temp(path+'Temp/')\n",
    "\n",
    "# run specified number of repetitions\n",
    "for i in range(reps):\n",
    "    \n",
    "    # print repetition\n",
    "    print('Repetition: ',i+1)\n",
    "    \n",
    "    # seed\n",
    "    np.random.seed(i)\n",
    "    torch.manual_seed(i)\n",
    "    \n",
    "    # delete all simulation files in Temp folder\n",
    "    del_sim(path+'Temp/')\n",
    "    \n",
    "    # simulate data for given setting and parameters(save csv-files in Temp)\n",
    "    sim_data(setting=setting, params=params, tau=tau, fac_beta=fac_beta, test_size=test_size, l=sim_length, path=path+'Temp/', lags=1, verbose=False)\n",
    "    \n",
    "    # split all data into train, val, and test (save nzp-files in Temp)\n",
    "    split_data(setting=setting, params=params, path=path+'Temp/', test_size=test_size)\n",
    "    \n",
    "    # check simulated data\n",
    "    #sim = pd.read_csv(path+'Temp/sim1.csv' ,sep=',',na_values = 'NA')\n",
    "    #data1 = np.load(path+'Temp/sim2_%s.npz' %sim.columns[0])\n",
    "    #data2 = np.load(path+'Temp/sim2_%s.npz' %sim.columns[1])\n",
    "    #plt.plot(data1['y_test'])\n",
    "    #plt.plot(data2['y_test'])\n",
    "    #plt.show()\n",
    "    #del data1,data2\n",
    "             \n",
    "    # DL forecast\n",
    "    # if DL: get combination forecasts\n",
    "    if str_model == 'RNN' or str_model =='LSTM' or str_model =='GRU':\n",
    "        \n",
    "        # set parameters\n",
    "        batch_size = 256                   # batch size\n",
    "        input_dim = lags                  # number of lagged features in X\n",
    "        hidden_dim = 10                   # number of hidden nodes per layer\n",
    "        layer_dim = 1                     # number of layers\n",
    "        output_dim = 1                    # output dimension (1 for univariate output)\n",
    "        dropout = 0                       # dropout proportion (only before the last sequential layer)\n",
    "        learning_rate = 1e-3              # learning rate for Adam optimizer\n",
    "        weight_decay = 1e-6               # weight decay for Adam optimizer\n",
    "\n",
    "        # save model parameters in dict\n",
    "        model_params = {'input_dim': input_dim, 'hidden_dim' : hidden_dim,'layer_dim' : layer_dim, 'output_dim' : output_dim, 'dropout_prob' : dropout}\n",
    "        \n",
    "        # train model\n",
    "        results = []\n",
    "        for j in range(len(params)):\n",
    "            print('Parameter combination: ', j+1,'/',len(params))\n",
    "            df_sim = train_loop(model_name=str_model,model_params=model_params,num_sim=j+1,str_sims=str_sims,path=path,batch_size=batch_size, learning_rate=learning_rate, weight_decay=weight_decay)\n",
    "            results.append(df_sim)\n",
    "        \n",
    "    \n",
    "    # forecast AR model\n",
    "    if str_model == 'AR':\n",
    "        \n",
    "        results = []\n",
    "        for j in range(len(params)):\n",
    "            print('Parameter combination: ', j+1,'/',len(params))\n",
    "            df_sim = train_loop_ar(path=path,num_sim=j+1,str_sims=str_sims,plot_res=False)\n",
    "            results.append(df_sim)\n",
    "    \n",
    "    # forecast ARIMA model\n",
    "    if str_model == 'ARIMA':\n",
    "        \n",
    "        params_list = list(itertools.product(params[0],params[1]))\n",
    "        \n",
    "        results = []\n",
    "        for j in range(len(params_list)):\n",
    "            print('Parameter combination: ', j+1,'/',len(params_list))\n",
    "            df_sim = train_loop_arima(path=path,num_sim=j+1,str_sims=str_sims)\n",
    "            results.append(df_sim)\n",
    "    \n",
    "    # forecast GARCH model\n",
    "    #if str_model == 'GARCH':\n",
    "        \n",
    "    #    results = []\n",
    "    #    for j in range(len(params)):\n",
    "    #        print('Parameter combination: ', j+1,'/',len(params))\n",
    "    #        df_sim = train_loop_garch(path=path,num_sim=j+1,str_sims=str_sims)\n",
    "    #        results.append(df_sim)\n",
    "        \n",
    "    \n",
    "    # save intermediate results\n",
    "    new_results = np.expand_dims(np.asarray(results),axis=1)\n",
    "    if i==0:\n",
    "        np.save(path+'Temp/interm_results.npy',new_results)\n",
    "    else:\n",
    "        prev_results = np.load(path+'Temp/interm_results.npy')\n",
    "        all_results = np.concatenate((prev_results,new_results),axis=1) # shape: no. of params x rep x no. of settings x no. of metrics\n",
    "        np.save(path+'Temp/interm_results.npy',all_results)\n",
    "        del prev_results\n",
    "    \n",
    "    # calculate metrics\n",
    "    arr_results = np.load(path+'Temp/interm_results.npy')\n",
    "    arr_mean, arr_std, arr_min, arr_max, arr_median = get_results(arr_results) # aggregate over reps (axis 1)  \n",
    "    np.savez(path+'Results/'+setting+'_'+str_model+'_results.npz',mean=arr_mean,std=arr_std,minimum=arr_min,maximum=arr_max,median=arr_median)\n",
    "    del arr_results\n",
    "    \n",
    "    if (i < 10) | (i % 50 == 0):\n",
    "        print('Elapsed: %s' %time_format(time.time() - timer_start))\n",
    "\n",
    "print('Simulation end: %s' %time.ctime(int(time.time())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7baf006c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#with np.load(path+'Results/'+setting+'_'+str_model+'_results.npz') as data:\n",
    "#    print(data['mean'].shape, data['std'].shape, data['minimum'].shape, data['maximum'].shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
