{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fecc892",
   "metadata": {},
   "source": [
    "# Sequential deep learning models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b594a3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import numpy as np\n",
    "#import matplotlib.pyplot as plt\n",
    "#import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8eb9215",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, mean_absolute_percentage_error\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.optim as optim\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15717ce5",
   "metadata": {},
   "source": [
    "### Vanilla RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ad715efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim, dropout_prob):\n",
    "        super(RNNModel, self).__init__()\n",
    "\n",
    "        # Defining the number of layers and the nodes in each layer\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.layer_dim = layer_dim\n",
    "\n",
    "        # RNN layers\n",
    "        self.rnn = nn.RNN(\n",
    "            input_dim, hidden_dim, layer_dim, batch_first=True, dropout=dropout_prob\n",
    "        )\n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Initializing hidden state for first input with zeros\n",
    "        h0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim, device=x.device).requires_grad_()\n",
    "\n",
    "        # Forward propagation by passing in the input and hidden state into the model\n",
    "        self.rnn.flatten_parameters() # ------------------------------------------------------------------\n",
    "        out, h0 = self.rnn(x, h0.detach())\n",
    "\n",
    "        # Reshaping the outputs in the shape of (batch_size, seq_length, hidden_size)\n",
    "        # so that it can fit into the fully connected layer\n",
    "        out = out[:, -1, :]\n",
    "\n",
    "        # Convert the final state to our desired output shape (batch_size, output_dim)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60865e8",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f04bfae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim, dropout_prob):\n",
    "        super(LSTMModel, self).__init__()\n",
    "\n",
    "        # Defining the number of layers and the nodes in each layer\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.layer_dim = layer_dim\n",
    "\n",
    "        # LSTM layers\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_dim, hidden_dim, layer_dim, batch_first=True, dropout=dropout_prob\n",
    "        )\n",
    "\n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Initializing hidden state for first input with zeros\n",
    "        h0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim, device=x.device).requires_grad_()\n",
    "\n",
    "        # Initializing cell state for first input with zeros\n",
    "        c0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim, device=x.device).requires_grad_()\n",
    "\n",
    "        # We need to detach as we are doing truncated backpropagation through time (BPTT)\n",
    "        # If we don't, we'll backprop all the way to the start even after going through another batch\n",
    "        # Forward propagation by passing in the input, hidden state, and cell state into the model\n",
    "        self.lstm.flatten_parameters() # ------------------------------------------------------------------\n",
    "        out, (hn, cn) = self.lstm(x, (h0.detach(), c0.detach()))\n",
    "\n",
    "        # Reshaping the outputs in the shape of (batch_size, seq_length, hidden_size)\n",
    "        # so that it can fit into the fully connected layer\n",
    "        out = out[:, -1, :]\n",
    "\n",
    "        # Convert the final state to our desired output shape (batch_size, output_dim)\n",
    "        out = self.fc(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2def0b6",
   "metadata": {},
   "source": [
    "### GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "13e39c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim, dropout_prob):\n",
    "        super(GRUModel, self).__init__()\n",
    "\n",
    "        # Defining the number of layers and the nodes in each layer\n",
    "        self.layer_dim = layer_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        # GRU layers\n",
    "        self.gru = nn.GRU(\n",
    "            input_dim, hidden_dim, layer_dim, batch_first=True, dropout=dropout_prob\n",
    "        )\n",
    "\n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Initializing hidden state for first input with zeros\n",
    "        h0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim, device=x.device).requires_grad_()\n",
    "\n",
    "        # Forward propagation by passing in the input and hidden state into the model\n",
    "        self.gru.flatten_parameters() # ------------------------------------------------------------------\n",
    "        out, _ = self.gru(x, h0.detach())\n",
    "\n",
    "        # Reshaping the outputs in the shape of (batch_size, seq_length, hidden_size)\n",
    "        # so that it can fit into the fully connected layer\n",
    "        out = out[:, -1, :]\n",
    "\n",
    "        # Convert the final state to our desired output shape (batch_size, output_dim)\n",
    "        out = self.fc(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74012912",
   "metadata": {},
   "source": [
    "### Model initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "dfbac369",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(model, model_params):\n",
    "    models = {\n",
    "        \"rnn\": RNNModel,\n",
    "        \"lstm\": LSTMModel,\n",
    "        \"gru\": GRUModel,\n",
    "    }\n",
    "    return models.get(model.lower())(**model_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9808925",
   "metadata": {},
   "source": [
    "### Optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "6b359b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimization:\n",
    "    def __init__(self, model, loss_fn, optimizer):\n",
    "        self.model = model\n",
    "        self.loss_fn = loss_fn\n",
    "        self.optimizer = optimizer\n",
    "        self.train_losses = []\n",
    "        self.val_losses = []\n",
    "    \n",
    "    def train_step(self, x, y):\n",
    "        # Sets model to train mode\n",
    "        self.model.train()\n",
    "\n",
    "        # Makes predictions\n",
    "        yhat = self.model(x)\n",
    "\n",
    "        # Computes loss\n",
    "        loss = self.loss_fn(y, yhat)\n",
    "\n",
    "        # Computes gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # Updates parameters and zeroes gradients\n",
    "        self.optimizer.step()\n",
    "        self.optimizer.zero_grad()\n",
    "\n",
    "        # Returns the loss\n",
    "        return loss.item()\n",
    "    \n",
    "    def train(self, train_loader, val_loader, batch_size=64, n_epochs=50, n_features=1):\n",
    "        #model_path = f'{self.model}_{datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}'\n",
    "        \n",
    "        # train on GPU\n",
    "        device = torch.device('cuda')\n",
    "        \n",
    "        best_loss = np.infty\n",
    "        best_train_loss = np.infty\n",
    "        stop_criterion = 1e-5\n",
    "        cnt = 0\n",
    "        patience = 100\n",
    "\n",
    "        for epoch in range(1, n_epochs + 1):\n",
    "            batch_losses = []\n",
    "            for x_batch, y_batch in train_loader:\n",
    "                x_batch = x_batch.view([batch_size, -1, n_features]).to(device)\n",
    "                y_batch = y_batch.to(device)\n",
    "                b_loss = self.train_step(x_batch, y_batch)\n",
    "                batch_losses.append(b_loss)\n",
    "            training_loss = np.mean(batch_losses)\n",
    "            self.train_losses.append(training_loss)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                batch_val_losses = []\n",
    "                for x_val, y_val in val_loader:\n",
    "                    x_val = x_val.view([batch_size, -1, n_features]).to(device)\n",
    "                    y_val = y_val.to(device)\n",
    "                    self.model.eval()\n",
    "                    yhat = self.model(x_val)\n",
    "                    val_loss = self.loss_fn(y_val, yhat).item()\n",
    "                    batch_val_losses.append(val_loss)\n",
    "                val_loss = np.mean(batch_val_losses)\n",
    "                self.val_losses.append(val_loss)\n",
    "\n",
    "                # safe model with smallest validation loss\n",
    "                if (val_loss < best_loss):\n",
    "                    best_loss = val_loss\n",
    "                    best_epoch = epoch\n",
    "                    best_model = deepcopy(self.model)\n",
    "                    \n",
    "                # early stopping\n",
    "                if ((best_train_loss - training_loss) > stop_criterion):\n",
    "                    best_train_loss = training_loss\n",
    "                    cnt = 0\n",
    "                else:\n",
    "                    cnt += 1\n",
    "                if cnt == patience:\n",
    "                    break\n",
    "\n",
    "            #if (epoch % 100 == 0):\n",
    "            #    print(\n",
    "            #        f\"[{epoch}/{n_epochs}] Training loss: {training_loss:.4f}\\t Validation loss: {val_loss:.4f}\"\n",
    "            #      )\n",
    "\n",
    "        #torch.save(self.model.state_dict(), model_path)\n",
    "        return best_model, best_loss\n",
    "\n",
    "    def evaluate(self, best_model, test_loader, batch_size=1, n_features=1):\n",
    "        # evaluate on GPU\n",
    "        device = torch.device('cuda')\n",
    "        model = deepcopy(best_model)\n",
    "        with torch.no_grad():\n",
    "            predictions = []\n",
    "            values = []\n",
    "            for x_test, y_test in test_loader:\n",
    "                x_test = x_test.view([batch_size, -1, n_features]).to(device)\n",
    "                y_test = y_test.to(device)\n",
    "                model.eval()\n",
    "                yhat = model(x_test)\n",
    "                predictions.append(yhat.to(device).detach().cpu().numpy())\n",
    "                values.append(y_test.to(device).detach().cpu().numpy())\n",
    "\n",
    "        return predictions, values\n",
    "    \n",
    "    def plot_losses(self):\n",
    "        plt.plot(self.train_losses, label=\"Training loss\")\n",
    "        plt.plot(self.val_losses, label=\"Validation loss\")\n",
    "        plt.legend()\n",
    "        plt.title(\"Losses\")\n",
    "        plt.show()\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93bcc473",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "fd565829",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_transform(scaler, df, columns):\n",
    "    for col in columns:\n",
    "        df[col] = scaler.inverse_transform(df[col])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "8424a5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_predictions_dl(predictions, values, df_test, scaler):\n",
    "    vals = np.concatenate(values, axis=0).ravel()\n",
    "    preds = np.concatenate(predictions, axis=0).ravel()\n",
    "    df_result = pd.DataFrame(data={\"value\": vals, \"prediction\": preds})\n",
    "    df_result = df_result.sort_index()\n",
    "    df_result = inverse_transform(scaler, df_result, [[\"value\", \"prediction\"]])\n",
    "    return df_result\n",
    "\n",
    "#def calculate_metrics(df):\n",
    "#    return {'rmse' : mean_squared_error(df.value, df.prediction) ** 0.5,\n",
    "#            'mae' : mean_absolute_error(df.value, df.prediction),\n",
    "#            'mape': mean_absolute_percentage_error(df.value, df.prediction),\n",
    "#            'r2' : r2_score(df.value, df.prediction)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba855e11",
   "metadata": {},
   "source": [
    "### Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b30c97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(model_name, model_params,num_sim,str_sims,path,seed,lags=1,batch_size = 64,n_epochs = 500):\n",
    "    \n",
    "    # train on GPU\n",
    "    device = torch.device('cuda')\n",
    "    best_seeds = np.zeros(len(str_sims))\n",
    "    results = []\n",
    "    preds = []\n",
    "\n",
    "    # loop over all datasets in the simulation setup\n",
    "    for j in range(len(str_sims)):\n",
    "        \n",
    "        # print dataset\n",
    "        print('No. of dataset: ', j+1,'/',len(str_sims))\n",
    "\n",
    "        # load data\n",
    "        data_name = 'sim'+str(num_sim)+'_'+str_sims[j]\n",
    "        with np.load(path+'Temp/'+data_name+'.npz') as data:\n",
    "            # extract data and the given number of lagged features\n",
    "            X_train = data['X_train'][:,:lags]\n",
    "            X_val = data['X_val'][:,:lags]\n",
    "            X_test = data['X_test'][:,:lags]\n",
    "            y_train = data['y_train']\n",
    "            y_val = data['y_val']\n",
    "            y_test = data['y_test']\n",
    "\n",
    "        # scale the data to 0-1\n",
    "        scaler = MinMaxScaler()\n",
    "\n",
    "        X_train_arr = scaler.fit_transform(X_train)\n",
    "        X_val_arr = scaler.transform(X_val)\n",
    "        X_test_arr = scaler.transform(X_test)\n",
    "\n",
    "        y_train_arr = scaler.fit_transform(y_train)\n",
    "        y_val_arr = scaler.transform(y_val)\n",
    "        y_test_arr = scaler.transform(y_test)\n",
    "\n",
    "        # convert data to tensors\n",
    "        train_features = torch.Tensor(X_train_arr)\n",
    "        train_targets = torch.Tensor(y_train_arr)\n",
    "        val_features = torch.Tensor(X_val_arr)\n",
    "        val_targets = torch.Tensor(y_val_arr)\n",
    "        test_features = torch.Tensor(X_test_arr)\n",
    "        test_targets = torch.Tensor(y_test_arr)\n",
    "\n",
    "        # build tensor dataset\n",
    "        train = TensorDataset(train_features, train_targets)\n",
    "        val = TensorDataset(val_features, val_targets)\n",
    "        test = TensorDataset(test_features, test_targets)\n",
    "\n",
    "        # get batched data\n",
    "        train_loader = DataLoader(train, batch_size=batch_size, shuffle=False, drop_last=True) \n",
    "        val_loader = DataLoader(val, batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "        test_loader = DataLoader(test, batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "        test_loader_one = DataLoader(test, batch_size=1, shuffle=False, drop_last=True)\n",
    "\n",
    "        df_sim = pd.DataFrame()\n",
    "        test_preds = []\n",
    "        best_loss = np.infty\n",
    "\n",
    "        # loop over all model seeds\n",
    "        model_num = 0\n",
    "        for i in seed:\n",
    "            \n",
    "            # print model number\n",
    "            if ((model_num + 1) % 5 == 0): \n",
    "                print('Model seed: ',model_num + 1,'/',len(seed))\n",
    "\n",
    "            # initialise model\n",
    "            torch.manual_seed(i)\n",
    "            # train on GPU\n",
    "            #device = torch.device('cuda')\n",
    "            model = get_model(model_name, model_params).to(device)\n",
    "\n",
    "            # create loss function and optimizer\n",
    "            loss_fn = nn.MSELoss(reduction=\"mean\")\n",
    "            optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "            opt = Optimization(model=model, loss_fn=loss_fn, optimizer=optimizer)\n",
    "            \n",
    "            # train the model\n",
    "            best_model_out, val_loss = opt.train(train_loader, test_loader, batch_size=batch_size, n_epochs=n_epochs, n_features=input_dim)\n",
    "            if (val_loss < best_loss):\n",
    "                best_loss = val_loss\n",
    "                best_seeds[j] = model_num\n",
    "            #opt.plot_losses()\n",
    "\n",
    "            # evaluate on test set\n",
    "            predictions, values = opt.evaluate(best_model_out, test_loader_one, batch_size=1, n_features=input_dim)\n",
    "            df_result = format_predictions_dl(predictions, values, X_test, scaler)\n",
    "            result_metrics = calculate_metrics(df_result)\n",
    "            #print(result_metrics)\n",
    "\n",
    "            # append metrics on test set\n",
    "            df_metrics = pd.DataFrame(np.expand_dims((result_metrics['rmse'],result_metrics['mae'],result_metrics['mape'],result_metrics['r2'],),axis=0),columns=['rmse','mae','mape','r2'])\n",
    "            df_sim = pd.concat([df_sim,df_metrics],axis=0, ignore_index=True)\n",
    "\n",
    "            # append test predictions\n",
    "            test_preds.append(np.asarray(df_result))\n",
    "            \n",
    "            # counter\n",
    "            model_num += 1\n",
    "\n",
    "        # save results\n",
    "        results.append(df_sim)  \n",
    "\n",
    "        # save test predictions\n",
    "        preds.append(np.asarray(test_preds))\n",
    "    \n",
    "    return np.asarray(results), np.asarray(preds), best_seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "afc95a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#path = 'C:/Users/Meier/Dropbox (Institut für Statistik)/Structural Breaks + DL/Simulation/Python Code/' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "797dce80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set data parameters\n",
    "#batch_size = 64           # batch size\n",
    "#lags = 1                  # number of lagged features in X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "daf9a764",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set simulation parameters\n",
    "#model_name = 'gru'                # 'rnn', 'lstm' or 'gru'\n",
    "#seed = np.arange(2)              # number of models to run per dataset\n",
    "#n_epochs = 500                    # number of epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "adc20d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set model/training parameters\n",
    "#input_dim = lags                  # number of lagged features in X\n",
    "#hidden_dim = 10                   # number of hidden nodes per layer\n",
    "#layer_dim = 1                     # number of layers\n",
    "#output_dim = 1                    # output dimension (1 for univariate output)\n",
    "#dropout = 0                       # dropout proportion (only before the last sequential layer)\n",
    "#learning_rate = 1e-3              # learning rate for Adam optimizer\n",
    "#weight_decay = 1e-6               # weight decay for Adam optimizer\n",
    "\n",
    "# save model parameters in dict\n",
    "#model_params = {'input_dim': input_dim, 'hidden_dim' : hidden_dim,'layer_dim' : layer_dim, 'output_dim' : output_dim, 'dropout_prob' : dropout}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "77de7b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#str_sims = ['Ref','Tau0.1Ref','Tau0.1Beta0.5','Tau0.1Beta1.0','Tau0.1Beta2.0','Tau0.2Ref','Tau0.2Beta0.5','Tau0.2Beta1.0','Tau0.2Beta2.0','Tau0.3Ref','Tau0.3Beta0.5','Tau0.3Beta1.0','Tau0.3Beta2.0','Tau0.4Ref','Tau0.4Beta0.5','Tau0.4Beta1.0','Tau0.4Beta2.0','Tau0.5Ref','Tau0.5Beta0.5','Tau0.5Beta1.0','Tau0.5Beta2.0','Tau0.6Ref','Tau0.6Beta0.5','Tau0.6Beta1.0','Tau0.6Beta2.0','Tau0.7Ref','Tau0.7Beta0.5','Tau0.7Beta1.0','Tau0.7Beta2.0'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050db807",
   "metadata": {},
   "outputs": [],
   "source": [
    "#results, preds, best_seeds = train_loop(model_name=model_name, model_params=model_params,num_sim=1,str_sims=str_sims,path=path,seed=seed,lags=1,batch_size = 64,n_epochs = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1960648",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
