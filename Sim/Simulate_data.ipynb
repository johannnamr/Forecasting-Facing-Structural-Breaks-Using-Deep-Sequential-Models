{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb2887d2",
   "metadata": {},
   "source": [
    "# Simulate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17a2d501",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from statsmodels.tsa.arima_process import ArmaProcess\n",
    "from statsmodels.tsa.api import SARIMAX\n",
    "from arch.univariate import arch_model\n",
    "from sklearn.preprocessing import MinMaxScaler,MaxAbsScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7ae8f2",
   "metadata": {},
   "source": [
    "Functions to simulate data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7f9c75ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim_data(setting, params, tau, fac_beta, test_size, l, path, lags=1, verbose=False):\n",
    "    \n",
    "    # zip parameter combinations if necessary\n",
    "    if setting == 'ARIMA':\n",
    "        params_list = list(itertools.product(params[0],params[1]))\n",
    "    else:\n",
    "        params_list = params\n",
    "    \n",
    "    # loop over all parameter combinations\n",
    "    num_ref = 0\n",
    "    num_tau = 0\n",
    "    num_beta = 0\n",
    "    for param in range(len(params_list)):  \n",
    "        \n",
    "        # simulate data withouth break\n",
    "        if setting == 'AR':\n",
    "            ar = np.array([1, -params_list[param]])\n",
    "            ma = np.array([1])\n",
    "            model = ArmaProcess(ar, ma)\n",
    "            series = model.generate_sample(nsample=l+lags)\n",
    "        if setting == 'ARIMA':\n",
    "            zero_dat = np.zeros(l)\n",
    "            model = SARIMAX(zero_dat, order=(1,1,1), initialization='diffuse')\n",
    "            series = model.simulate([params_list[param][0],1,params_list[param][1]],l)\n",
    "        if setting == 'GARCH':\n",
    "            model = arch_model(None, mean='Zero', vol='Garch', p=1, q=1, dist=\"Normal\")\n",
    "            series = np.array(model.simulate([params_list[param][0],0,params_list[param][1]], l).data)\n",
    "        num_ref += 1\n",
    "        \n",
    "        # scale the data to [-1,1]\n",
    "        #scaler = MinMaxScaler()\n",
    "        scaler = MaxAbsScaler()\n",
    "        series = scaler.fit_transform(series.reshape(-1, 1))\n",
    "        \n",
    "        # dataframe from simulated series\n",
    "        df = pd.DataFrame(series, columns=['Ref'])\n",
    "        if verbose:\n",
    "            print(np.min(series), np.max(series))\n",
    "            plt.plot(series, color='green')\n",
    "        \n",
    "        # loop over break locations\n",
    "        for t in tau:\n",
    "            num_tau += 1\n",
    "            \n",
    "            # get break location\n",
    "            break_loc = int((1-test_size)*t*l+lags) # location at specified proportion of training set (excluding the observations needed for lags)\n",
    "            \n",
    "            # save simulated series after breakpoint\n",
    "            series2 = np.empty_like(series)\n",
    "            series2[:] = np.nan\n",
    "            series2[(break_loc-lags):] = series.copy()[(break_loc-lags):]\n",
    "            colstr = 'Tau'+str(t)+'Ref'\n",
    "            df2 = pd.DataFrame(series2, columns=[colstr])\n",
    "            df = pd.concat([df,df2], axis=1)\n",
    "            if verbose:\n",
    "                plt.plot(series2, color='red')\n",
    "            \n",
    "            # loop over break sizes\n",
    "            for fb in fac_beta:\n",
    "                num_beta += 1\n",
    "                \n",
    "                # get break size\n",
    "                beta = fb*np.std(series[lags:]) # determine the size of the break\n",
    "            \n",
    "                # add single mean break\n",
    "                series_break = series.copy()\n",
    "                series_break[lags:break_loc] += beta # add constant\n",
    "            \n",
    "                # save simulated series with break\n",
    "                colstr = 'Tau'+str(t)+'Beta'+str(fb)\n",
    "                df_break = pd.DataFrame(series_break, columns=[colstr])\n",
    "                df = pd.concat([df,df_break], axis=1)\n",
    "            if verbose:\n",
    "                plt.plot(series_break, color='blue')\n",
    "                print(np.min(series_break), np.max(series_break))\n",
    "                print(beta)\n",
    "            \n",
    "        # save all simulated series\n",
    "        df.to_csv(path+'sim'+str(num_ref)+'.csv',na_rep='NA', index=False)\n",
    "        if verbose:\n",
    "            print('sim'+str(num_ref))\n",
    "            plt.show()\n",
    "            print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a5aa2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim_data_2breaks(setting, params, tau, fac_beta, test_size, l, path, lags=1, verbose=False):\n",
    "    \n",
    "    # zip parameter combinations if necessary\n",
    "    if setting == 'ARIMA':\n",
    "        params_list = list(itertools.product(params[0],params[1]))\n",
    "    else:\n",
    "        params_list = params\n",
    "    \n",
    "    # loop over all parameter combinations\n",
    "    num_ref = 0\n",
    "    num_tau = 0\n",
    "    num_beta = 0\n",
    "    for param in range(len(params_list)):  \n",
    "        \n",
    "        # simulate data withouth break\n",
    "        if setting == 'AR':\n",
    "            ar = np.array([1, -params_list[param]])\n",
    "            ma = np.array([1])\n",
    "            model = ArmaProcess(ar, ma)\n",
    "            series = model.generate_sample(nsample=l+lags)\n",
    "        if setting == 'ARIMA':\n",
    "            zero_dat = np.zeros(l)\n",
    "            model = SARIMAX(zero_dat, order=(1,1,1), initialization='diffuse')\n",
    "            series = model.simulate([params_list[param][0],1,params_list[param][1]],l)\n",
    "        if setting == 'GARCH':\n",
    "            model = arch_model(None, mean='Zero', vol='Garch', p=1, q=1, dist=\"Normal\")\n",
    "            series = np.array(model.simulate([params_list[param][0],0,params_list[param][1]], l).data)\n",
    "        num_ref += 1\n",
    "        \n",
    "        # scale the data to [-1,1]\n",
    "        #scaler = MinMaxScaler()\n",
    "        scaler = MaxAbsScaler()\n",
    "        series = scaler.fit_transform(series.reshape(-1, 1))\n",
    "        \n",
    "        # save simulated series\n",
    "        df = pd.DataFrame(series, columns=['Ref'])\n",
    "        if verbose:\n",
    "            plt.plot(series, color='green')\n",
    "            plt.show()\n",
    "        \n",
    "        # loop over break locations\n",
    "        for t in range(len(tau)):\n",
    "            num_tau += 1\n",
    "            \n",
    "            # get break locations\n",
    "            break_loc1 = int((1-test_size)*tau[t][0]*l+lags) # location at specified proportion of training set (excluding the observations needed for lags)\n",
    "            break_loc2 = int((1-test_size)*tau[t][1]*l+lags) # location at specified proportion of training set (excluding the observations needed for lags)\n",
    "\n",
    "            \n",
    "            # save simulated series after breakpoint\n",
    "            series2 = np.empty_like(series)\n",
    "            series2[:] = np.nan\n",
    "            series2[(break_loc2-lags):] = series.copy()[(break_loc2-lags):]\n",
    "            colstr = 'Tau'+str(tau[t][0])+str(tau[t][1])+'Ref'\n",
    "            df2 = pd.DataFrame(series2, columns=[colstr])\n",
    "            df = pd.concat([df,df2], axis=1)\n",
    "            if verbose:\n",
    "                plt.plot(series2, color='red')\n",
    "            \n",
    "            # loop over break sizes\n",
    "            for fb in fac_beta:\n",
    "                num_beta += 1\n",
    "                \n",
    "                # get break size\n",
    "                beta = fb*np.std(series[lags:]) # determine the size of the break\n",
    "            \n",
    "                # add increasing double mean break\n",
    "                series_break = series.copy()\n",
    "                series_break[lags:break_loc1] += 2*beta # Break 1: add constant x 2\n",
    "                series_break[break_loc1:break_loc2] += beta # Break 2: add constant\n",
    "                \n",
    "                # add mean reverting double mean break\n",
    "                series_break2 = series.copy()\n",
    "                series_break2[break_loc1:break_loc2] += beta # Break 1+2: add constant between break points\n",
    "            \n",
    "                # save simulated series with breaks\n",
    "                colstr = 'Tau'+str(tau[t][0])+str(tau[t][1])+'Beta'+str(fb)+'inc'\n",
    "                df_break = pd.DataFrame(series_break, columns=[colstr])\n",
    "                colstr2 = 'Tau'+str(tau[t][0])+str(tau[t][1])+'Beta'+str(fb)+'rev'\n",
    "                df_break2 = pd.DataFrame(series_break2, columns=[colstr2])\n",
    "                df = pd.concat([df,df_break,df_break2], axis=1)\n",
    "            if verbose:\n",
    "                plt.plot(series_break, color='blue')\n",
    "                plt.plot(series_break2, color='orange')\n",
    "                plt.show()\n",
    "            \n",
    "        # save all simulated series\n",
    "        df.to_csv(path+'sim'+str(num_ref)+'.csv',na_rep='NA', index=False)\n",
    "        if verbose:\n",
    "            print('sim'+str(num_ref))\n",
    "            #plt.show()\n",
    "            print(df) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5cffd19",
   "metadata": {},
   "source": [
    "Functions to split sample into training and test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f1d6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_time_lags(df, col_name, n_lags):\n",
    "    df_n = df[[col_name]].copy()\n",
    "    for n in range(1, n_lags + 1):\n",
    "        df_n[f\"lag{n}\"] = df_n[col_name].shift(n)\n",
    "    df_n = df_n.iloc[n_lags:]\n",
    "    return df_n.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d423db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_label_split(df, target_col):\n",
    "    y = df[[target_col]]\n",
    "    X = df.drop(columns=[target_col])\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873c8fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(setting, params, path, test_size, lags=1):\n",
    "    \n",
    "    # set number of simulations per setting\n",
    "    if setting == 'AR':\n",
    "        num_sim = params.shape[0] \n",
    "    if setting == 'GARCH':\n",
    "        num_sim = len(params)              \n",
    "    if setting == 'ARIMA':\n",
    "        num_sim = params[0].shape[0]*params[1].shape[0] \n",
    "    \n",
    "    # loop over all DGP settings\n",
    "    for j in range(num_sim):\n",
    "\n",
    "        # load simulated data\n",
    "        sim = pd.read_csv(path+'sim%s.csv' %(j+1) ,sep=',',na_values = 'NA')\n",
    "\n",
    "        # loop over all break settings\n",
    "        for i in range(len(sim.columns)):\n",
    "\n",
    "            # get and save splits\n",
    "            df_generated = generate_time_lags(sim, sim.columns[i], lags)\n",
    "            X, y = feature_label_split(df_generated, sim.columns[i])\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, shuffle=False)\n",
    "            #print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "            if all([x in sim.columns[i] for x in ['Tau','Ref']]):\n",
    "                np.savez(path+'sim%s_%s.npz' %((j+1),sim.columns[i]), X_train=X_train.dropna(), X_test=X_test, y_train=y_train.dropna()[1:], y_test=y_test)\n",
    "            else:\n",
    "                np.savez(path+'sim%s_%s.npz' %((j+1),sim.columns[i]), X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test)\n",
    "    \n",
    "        del sim"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
